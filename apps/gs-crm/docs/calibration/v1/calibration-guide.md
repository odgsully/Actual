# Calibration Template — Fill-Out Guide & Column Reference

## How to Think About This Template

The calibration template has 29 columns but they serve **3 distinct purposes**. Understanding which group each column belongs to determines how strictly you need to match what's pre-filled vs. what you actually observe.

**Important:** The Calibration Template (`Renovation_Calibration_55_Template.xlsx`) is a **separate file** from the Analysis sheet generated by the ReportIt pipeline. They have different column layouts. This document covers the calibration template. The Analysis sheet changes are documented at the bottom.

---

## Column Role Hierarchy

| Column | Name | Fed to AI? | Used in Training Loop? | Role |
|--------|------|-----------|----------------------|------|
| **R** | Your Reno Score (1-10) | No | Yes — **is** the ground truth | The answer key the AI gets benchmarked against |
| **S** | Your Reno Year Est. | No | Yes — recency cross-check | Validates AI's era estimation from photos |
| **T** | Kitchen Score (1-10) | No | Yes — sub-score debugging | Reveals which room the AI misjudges |
| **U** | Bath Score (1-10) | No | Yes — sub-score debugging | Reveals which room the AI misjudges |
| **V** | Exterior Score (1-10) | No | Yes — sub-score debugging | Reveals which room the AI misjudges |
| **W** | Design Cohesion (1-10) | No | Yes — sub-score debugging | Catches mismatched-finish scoring errors |
| **B** | Dwelling Type | No | Yes — error analysis grouping | Diagnose bias by property type |
| **C** | Price Range | No | Yes — error analysis grouping | Diagnose bias by price tier |
| **D** | Target Reno Tier | No | No | Shopping list — guides FlexMLS search |
| **E** | Target Score Range | No | No | Shopping list — confirms you're in the right bracket |
| **F** | Purpose | No | No | Shopping list — describes the archetype to hunt for |
| **G** | Bias Anchor? | No | No | Shopping list — flags the 10 most important slots |
| **H–Q** | MLS data (address, price, sqft, etc.) | No | No | Property facts — objective data from the listing |
| **X** | Key Indicators / Notes | No | No | Your notes — documents what you observed |
| **Y–AB** | Photo checklists | No | No | Validation — ensures photo coverage for scoring |
| **AC** | URL | No | No | Reference link back to listing |

---

## Three Column Groups

### Group 1: Shopping List (Pre-filled — Columns D, E, F, G)

These guide your FlexMLS search. They describe the **archetype** you're looking for in each slot.

**How strictly to match:** Loosely. The Purpose column (F) is a shorthand, not a spec sheet. Example:

- Slot #8 says "Kitchen-only update on entry SFR"
- You find a property where the kitchen was updated **plus** some bathroom work, but you still score it a 3-4
- **That's a valid pick.** The purpose is describing the general tier (partial update), not requiring literal kitchen-only renovation

**When to actually swap a property:** Only if the score wouldn't land in the target tier (Column E) at all. If you're filling a Tier 2 slot (target 3-4) but the property is really a 6, find a different one — you'd have a gap in Tier 2 coverage.

### Group 2: Error Analysis Metadata (Columns B, C)

These are **not fed to the vision model** — the AI only sees property photos. But they serve a critical second purpose after calibration runs.

Step 7 of the calibration process uses B and C to diagnose systematic AI errors:

- **Dwelling type bias** (Column B): Does the AI consistently overscore condos vs SFRs at the same material quality? Slice results by dwelling type to find out.
- **Price tier bias** (Column C): Does the AI assume expensive = renovated? Slice results by price range to catch this.

This is why the calibration set is stratified across dwelling types and price ranges — not to give the AI that context, but to ensure you can detect blind spots in specific categories.

### Group 3: Ground Truth (Columns R, S, T–W)

This is what the AI gets calibrated against. **Your honest assessment is everything here.**

- **Column R (Overall Reno Score)**: The single most important column. The median of 3 raters' scores becomes the benchmark the AI must match.
- **Column S (Reno Year Estimate)**: The AI outputs an estimated renovation year from photos. Your estimate here validates whether the AI's era detection is accurate. Score materials by era: oil-rubbed bronze = 2008-2014, matte black = 2018+, brushed gold = 2022+, grey LVP = 2017-2022, white oak = 2023+.
- **Columns T–W (Sub-scores)**: Kitchen, Bath, Exterior, Design Cohesion. If a tier systematically fails calibration, sub-scores reveal *which room type* the AI is misjudging.

**The vision AI never sees these scores during inference.** It sees photos → outputs its own score → that score gets compared to Column R. If accuracy < 80% within 1 point, the prompt gets tuned and re-run.

---

## The Pipeline: What the AI Actually Receives

```
Property photos (extracted from 7-Photo Flyer PDF)
    ↓
Vision API + renovation scoring prompt
    ↓
AI outputs: numeric score (1-10) + renovation year estimate
    ↓
Compare AI score vs Column R ground truth (median of 3 raters)
    ↓
If accuracy < 80%: analyze errors by Column B (dwelling type) and Column C (price range)
    ↓
Adjust prompt → re-run → iterate
```

The AI receives **only photos**. No dwelling type, no price, no purpose description, no address. This is intentional — the model must score renovation quality from visual evidence alone, independent of price or location.

---

## How Scores Feed Into the Live Pipeline

The calibration template trains the AI. The AI then populates the **Analysis sheet** (a different file). Here's how the 1-10 score is consumed:

### Tier Mapping (1-10 → 3 tiers)

| Tier | Score Range | Label | Analysis Use |
|------|-----------|-------|-------------|
| Low | 1-3 | Original/minimal | Baseline for premium calculations |
| Mid | 4-6 | Partial renovation | Cosmetic flip comparison |
| High | 7-10 | Full renovation | Premium tier |

### NOI 2D Multiplier Table (Score × Renovation Recency)

The pipeline uses both the renovation score AND the estimated renovation year to compute rent projections:

| Score | Fresh (0-3yr) | Mid (4-10yr) | Dated (11+yr) |
|-------|--------------|-------------|---------------|
| 1-2   | 0.45%        | 0.45%       | 0.45%         |
| 3-4   | 0.50%        | 0.48%       | 0.46%         |
| 5-6   | 0.58%        | 0.55%       | 0.50%         |
| 7-8   | 0.65%        | 0.60%       | 0.53%         |
| 9-10  | 0.70%        | 0.65%       | 0.55%         |

**Example:** A property scored 7/10 with renovation year 2024 (Fresh) → 0.65% multiplier → $2,600/mo rent on a $400K property. Same score with renovation year 2012 (Dated) → 0.53% → $2,120/mo.

**Blank renovation year = Mid recency** (neutral default — no penalty for not knowing).

### Scaled Improvement Costs (Analysis 22)

Renovation cost scales nonlinearly with current score:

| Starting Score | Cost Per Point | Example: +3 points |
|---------------|---------------|-------------------|
| 1-2 | $4,000-5,000/pt | Score 2→5: ~$16K |
| 3-4 | $7,000-10,000/pt | Score 4→7: ~$27K |
| 5-6 | $15,000-20,000/pt | Score 5→8: ~$55K |
| 7-8 | $30,000-45,000/pt | Score 7→10: ~$135K |

### Backward Compatibility

Old Analysis sheets with Y/N/0.5 values still work:
- `Y` → score 7 (standard flip, not high-quality)
- `0.5` → score 5
- `N` → score 2

---

## Renovation Score vs. Price — The Absolute Rule

**The score is absolute.** Same materials = same score, regardless of price.

A 6 is a 6 whether the house costs $300K or $1.3M. LVP + stock white shakers + basic quartz + stainless Frigidaire = 6. The vision AI scores materials and finishes from photos — it doesn't know the price.

What changes across price ranges is **how likely you are to find that score**:

| Price Range | How common is a 6? | Signal |
|-------------|-------------------|--------|
| $250K–$400K | Very common | Standard flip, appropriate for market |
| $400K–$700K | Common | Adequate flip, slightly thin for price |
| $700K–$1.2M | Uncommon | Underspent flip or spec builder |
| $1.2M–$2.5M | Rare | Value is in land/location, not finishes |

This is why **bias anchors** exist — they test expensive-but-dated and cheap-but-over-improved properties.

---

## Year Built vs. Renovation Score

A completely original 2006 home scores **3-4** (not 1-2) because 2006 builder-grade started with decent materials (granite, maple cabinets, brushed nickel). The 1-2 range is reserved for viscerally dated properties (1985 original with brass, oak, laminate, popcorn).

**The score reflects current condition relative to today's market, not how much work was done.** A 2006 original and a 1990 home with a kitchen-only update in 2015 can both land at 3-4 for completely different reasons.

---

## Quick Reference: Renovation Score Scale (1-10)

| Score | Label | Key Markers |
|-------|-------|-------------|
| 1-2 | Original/Dated | Honey oak, brass, popcorn ceilings, laminate counters |
| 3-4 | Partial Update | 1-2 rooms updated, mismatched finishes |
| 5-6 | Full Cosmetic Flip | White shaker, quartz/granite, LVP, subway tile |
| 7-8 | High-Quality Reno | Custom cabinets, designer tile, upgraded appliances |
| 9-10 | Luxury/Custom | Architect-designed, waterfall edge, pro appliances |

---

## Material Epoch Reference

Use these era markers when estimating renovation year (Column S) and calibrating your eye for material dating.

| Era | Period | Key Markers |
|-----|--------|-------------|
| Brass Era | Pre-1998 | Honey oak, brass fixtures, almond tile, laminate counters |
| Travertine Era | 1999-2008 | Espresso cabinets, granite, travertine floors |
| Gray Transition | 2009-2015 | White shaker begins, quartz begins, gray ceramic |
| Current Flip | 2016-present | White/gray shaker, quartz, LVP, matte black hardware |

---

## Design Cohesion (Column W) — What It Captures

Column W scores how visually consistent the renovation is across rooms. It naturally penalizes:

- Awkward load-bearing columns mid-room (reads as unfinished)
- Mismatched finishes between rooms (dated kitchen next to renovated bath)
- Half-measures (removed wall but left structural compromises visible)

**Structural/layout issues don't need a separate column.** W handles them because the vision AI sees the same visual awkwardness you do in photos. If it's obviously compromised in a photo, W scores it. If it's not visible in photos, the AI can't see it either.

---

## Mindset When Filling Out the Template

1. **Use Columns D/E/F to find properties** — they're your FlexMLS search criteria
2. **Score what you actually see in Column R** — not what the Purpose column says you should see
3. **Don't force a 1:1 match with Purpose** — real properties are messy. A "kitchen-only update" slot that has a property with kitchen + some bathroom work is more valuable than a forced pure example, because real-world properties the AI will encounter are equally messy
4. **The score must land in the target tier** — that's the only hard constraint. A Tier 2 slot needs a 3-4 score property. What specific rooms were updated is less important than the overall score landing in range
5. **Bias anchors (Column G = Y) are the most important 10 slots** — fill these first. They test the hardest cases: expensive but dated, cheap but over-improved
6. **Sub-scores (T–W) are your debugging insurance** — fill them honestly now so you have diagnostic data later if the AI struggles with specific room types
7. **Estimate renovation year (Column S)** — use material era cues. Don't stress about exact year; the pipeline uses 3 buckets (Fresh/Mid/Dated), not precise years

---

## Fill Order (Recommended)

1. **10 bias anchors first** (slots 3, 10, 18, 22, 26, 33, 38, 41, 47, 48) — most impactful for calibration accuracy
2. **Tier 3 (Full Flip) slots next** (12 properties) — the boundary between competent flip and quality renovation is the hardest visual distinction, so these need the most care
3. **Remaining slots** in any order

---

## Multifamily Column Guidance

Multifamily properties require adjusted scoring expectations due to different economics and photo coverage.

### Per-Door Pricing Context

Multifamily renovation quality correlates with per-door pricing, not gross sale price. A $600K fourplex at $150K/door will present differently from a $600K SFR. Expect lower per-unit finish quality at equivalent gross prices. This context informs your scoring expectations but the score itself remains absolute (same materials = same score).

### Exterior Scoring Weight

For multifamily properties, **exterior condition carries 25% weight** (vs 10% for residential SFR). Multifamily exteriors include shared areas, parking, landscaping, and building envelope that directly impact tenant perception and NOI. Score exterior more critically for multifamily.

### Missing Dwelling Type Column

Multifamily CSVs do not include a `Dwelling Type` column since all rows are multifamily by definition. When analyzing calibration error slices by dwelling type (Column B), multifamily properties will need to be grouped separately from the main residential calibration set.

### Full Multifamily Reference

See [`multifamily-scoring-guide.md`](./multifamily-scoring-guide.md) for complete multifamily scoring methodology, per-door benchmarks, and photo coverage requirements.

---

## Reference

- Calibration process: [`reportit-mlsupload-calibrate.md`](./reportit-mlsupload-calibrate.md)
- Template file: `[comps folder]/Renovation_Calibration_55_Template.xlsx`
- Scoring rubric: Sheet 2 of the template
- Room priority weights: Sheet 3 of the template

### Analysis Sheet Column Changes (Pipeline)

The **Analysis sheet** (generated by `analysis-sheet-generator.ts`) has been updated:

| Column | Field | Change |
|--------|-------|--------|
| R | RENOVATE_SCORE | Now accepts 1-10 numeric (was Y/N/0.5). Old values auto-coerce. |
| AD | RENO_YEAR_EST | **New column.** Enter estimated renovation year (e.g. 2018). Blank = Mid recency. |

These are different from the Calibration Template columns — do not conflate the two spreadsheets.
