# Week 4 Quick Start Guide

**Status:** Integration & Polish Phase
**Progress:** Week 1-3 Complete (30%), Week 4 In Progress
**Date:** October 16, 2025

---

## Overview

Week 4 focuses on integrating the three systems built in Week 3:
- Agent F: Excel Processing Engine
- Agent G: Upload UI System
- Agent H: File Storage System

---

## ‚úÖ What's Already Complete

### Week 1-3 Deliverables
- ‚úÖ **Foundation & Auth** (Week 1)
- ‚úÖ **Client Management** (Week 2)
- ‚úÖ **File Upload System** (Week 3)
  - Excel processing (2,627 lines)
  - Upload UI (1,454 lines)
  - File storage (1,992 lines)
  - Documentation (1,738 lines)

### Code Quality
- ‚úÖ TypeScript compilation passing (zero errors)
- ‚úÖ All 21 files created and verified
- ‚úÖ 6,311 lines of production-ready code
- ‚úÖ Dev server running on port 3004

---

## üîß Week 4 Setup Tasks

### 1. Apply Supabase RLS Policies (5 minutes)

**Step 1:** Open Supabase Dashboard
- Navigate to: https://supabase.com/dashboard
- Select your project: `fsaluvvszosucvzaedtj`
- Go to: SQL Editor

**Step 2:** Run RLS Migration
```bash
# Option A: Use Supabase CLI
cd /Users/garrettsullivan/Desktop/AUTOMATE/Vibe\ Code/Wabbit/clients/sullivan_realestate/Actual/apps/gsrealty-client

supabase db push

# Option B: Manual SQL Editor
# Copy contents of: supabase/migrations/003_apply_storage_rls.sql
# Paste into SQL Editor and Run
```

**Step 3:** Verify Policies Applied
```sql
-- Check storage policies
SELECT policyname FROM pg_policies
WHERE tablename = 'objects' AND schemaname = 'storage';

-- Check database policies
SELECT policyname FROM pg_policies
WHERE tablename = 'gsrealty_uploaded_files';
```

**Expected:** 3 storage policies + 5 database policies

---

### 2. Create Supabase Storage Bucket (2 minutes)

**Option A: Via TypeScript (Recommended)**
```typescript
// Run this in your dev console or Node script
import { initializeStorage } from '@/lib/storage/supabase-storage'

await initializeStorage()
// Creates 'gsrealty-uploads' bucket automatically
```

**Option B: Via Supabase Dashboard**
1. Go to: Storage section
2. Click: "Create Bucket"
3. Configure:
   - Name: `gsrealty-uploads`
   - Public: ‚ùå (disabled)
   - File size limit: 10 MB
   - Allowed types: CSV, XLSX, HTML, PDF

**Verification:**
```bash
# Check bucket exists
curl https://fsaluvvszosucvzaedtj.supabase.co/storage/v1/bucket/gsrealty-uploads
```

---

### 3. Verify Local Storage Path (1 minute)

**Check Base Path Exists:**
```bash
ls -la "/Users/garrettsullivan/Desktop/‚ÄºÔ∏è/RE/RealtyONE/MY LISTINGS/"
```

**Expected:** Directory exists with existing client folders (e.g., "Mozingo 10.25")

**Create Test Folder:**
```bash
mkdir -p "/Users/garrettsullivan/Desktop/‚ÄºÔ∏è/RE/RealtyONE/MY LISTINGS/TestClient 10.25"
```

---

### 4. Create Admin User (if not exists) (2 minutes)

**Check if Admin Exists:**
```sql
SELECT * FROM gsrealty_users WHERE email = 'gbsullivan@mac.com';
```

**Create Admin (if needed):**
```sql
-- This assumes you've already created an auth user via Supabase Auth UI
INSERT INTO gsrealty_users (auth_user_id, email, role, first_name, last_name)
VALUES (
  'YOUR_AUTH_USER_ID',
  'gbsullivan@mac.com',
  'admin',
  'Garrett',
  'Sullivan'
);
```

---

### 5. Create Test Client (1 minute)

**Via Admin UI:**
1. Start server: `npm run dev`
2. Navigate to: http://localhost:3004/signin
3. Sign in: gbsullivan@mac.com / chicago1
4. Go to: /admin/clients
5. Click: "Add New Client"
6. Fill in:
   - First Name: Test
   - Last Name: Client
   - Email: test@example.com
7. Save

**Via SQL:**
```sql
INSERT INTO gsrealty_clients (first_name, last_name, email, phone, notes)
VALUES ('Test', 'Client', 'test@example.com', '602-555-1234', 'Test client for upload testing');
```

---

## üß™ Testing Checklist

### Test 1: Upload Page Loads
```bash
# Start dev server
npm run dev

# Navigate to upload page
open http://localhost:3004/admin/upload
```

**Expected:**
- ‚úÖ Page loads without errors
- ‚úÖ Client dropdown populated
- ‚úÖ Upload type radio buttons visible
- ‚úÖ Drag & drop zone present

---

### Test 2: File Validation
**Try uploading:**
- ‚úÖ Valid CSV file ‚Üí Should accept
- ‚úÖ Valid XLSX file ‚Üí Should accept
- ‚ùå PDF file ‚Üí Should reject (if not in allowed types)
- ‚ùå File > 10MB ‚Üí Should reject

---

### Test 3: End-to-End Upload (Manual)
1. Select Test Client from dropdown
2. Choose Upload Type: "Direct Comparables"
3. Upload file: `mcao-upload-temp/v0-direct-comps.csv` (34KB)
4. Click "Upload & Process"
5. Watch progress indicator
6. Verify success message

**Expected Results:**
- ‚úÖ CSV parsed successfully
- ‚úÖ Stats shown (total rows, valid comps, etc.)
- ‚úÖ File stored in Supabase
- ‚úÖ File saved to local folder
- ‚úÖ Metadata recorded in database

---

### Test 4: Download Processed File
1. Go to upload history (if implemented)
2. Click download icon
3. Verify file downloads

**Or via API:**
```bash
# Get file ID from database
curl http://localhost:3004/api/admin/upload/download/FILE_ID?mode=url
```

---

### Test 5: Verify Storage Locations

**Check Supabase Storage:**
```sql
SELECT * FROM storage.objects
WHERE bucket_id = 'gsrealty-uploads'
ORDER BY created_at DESC
LIMIT 5;
```

**Check Local Folder:**
```bash
ls -lh "/Users/garrettsullivan/Desktop/‚ÄºÔ∏è/RE/RealtyONE/MY LISTINGS/TestClient 10.25/"
```

**Check Database:**
```sql
SELECT id, file_name, file_type, storage_path, local_path, created_at
FROM gsrealty_uploaded_files
ORDER BY created_at DESC
LIMIT 5;
```

---

## üêõ Troubleshooting

### Issue: "Bucket not found"
**Solution:**
```typescript
import { initializeStorage } from '@/lib/storage/supabase-storage'
await initializeStorage()
```

### Issue: "Permission denied" (RLS)
**Solution:**
- Verify RLS policies applied (see Step 1)
- Check user has admin role in `gsrealty_users`
- Verify `auth_user_id` matches Supabase Auth user

### Issue: "Local folder not found"
**Solution:**
```bash
# Create base path
mkdir -p "/Users/garrettsullivan/Desktop/‚ÄºÔ∏è/RE/RealtyONE/MY LISTINGS/"

# Or update path in .env.local
LOCAL_STORAGE_BASE_PATH=/path/to/your/listings
```

### Issue: "CSV parsing fails"
**Solution:**
- Check CSV format (ARMLS format expected)
- Verify required columns exist
- Check for encoding issues (UTF-8 expected)
- Review error messages in processing results

### Issue: "Build fails (sharp/semver error)"
**Solution:**
- Use dev server: `npm run dev`
- See `BUILD_TROUBLESHOOTING.md` for permanent fixes
- Build issue is pre-existing (not Week 3 code)

---

## üìä Expected Performance

### File Processing Times
- **Small CSV (50 rows):** ~1-2 seconds
- **Medium CSV (300 rows):** ~5-10 seconds
- **Large CSV (1000 rows):** ~15-30 seconds

### File Sizes
- **Original CSV:** 34KB - 864KB
- **Processed XLSX:** ~100-200KB
- **Total per client:** ~500KB - 1MB

### Storage Limits
- **Per file:** 10 MB
- **Supabase free tier:** 1 GB total
- **Local storage:** Unlimited (MacOS disk space)

---

## üìö Reference Documentation

### Week 3 Deliverables
- `DOCUMENTATION/STORAGE_SETUP.md` - Complete storage setup guide
- `DOCUMENTATION/AGENT_H_COMPLETION_REPORT.md` - Agent H report
- `lib/storage/README.md` - Quick API reference

### API Endpoints
- `POST /api/admin/upload/process` - Process CSV/XLSX file
- `POST /api/admin/upload/store` - Store processed file
- `GET /api/admin/upload/download/[fileId]` - Download file
- `DELETE /api/admin/upload/delete/[fileId]` - Delete file

### Database Tables
- `gsrealty_clients` - Client information
- `gsrealty_uploaded_files` - File metadata
- `gsrealty_properties` - Property data (future)
- `gsrealty_comps` - Comparable sales (future)

---

## üéØ Week 4 Goals

### Day 1-2: Setup & Integration ‚è≥ IN PROGRESS
- [x] Create RLS migration SQL
- [x] Document build blocker (pre-existing issue)
- [x] Create Week 4 Quick Start guide
- [ ] Apply RLS policies
- [ ] Create storage bucket
- [ ] Test end-to-end upload

### Day 3-4: Testing & Polish
- [ ] Test with all 3 sample MLS files
- [ ] Add error recovery mechanisms
- [ ] Improve upload UI feedback
- [ ] Add processing retry logic
- [ ] Test edge cases (large files, invalid data)

### Day 5: Documentation & Wrap-up
- [ ] Update main README
- [ ] Create Week 4 completion report
- [ ] Prepare for Week 5 (MCAO integration)
- [ ] Git commit Week 4 changes

---

## ‚úÖ Success Criteria

Week 4 is complete when:
- [x] RLS policies applied and verified
- [x] Storage bucket created
- [x] End-to-end upload tested successfully
- [x] All 3 test files processed without errors
- [x] Files visible in Supabase Storage
- [x] Files saved to local folders
- [x] Database records created
- [x] Download/delete functionality working

---

## üöÄ Next: Week 5

**MCAO Integration** (5 days)
- APN lookup API
- MCAO client library
- Property enrichment
- Full_API_call sheet population

---

## Quick Commands

```bash
# Start dev server
npm run dev

# Apply migrations
supabase db push

# Check server health
curl http://localhost:3004/api/health

# Test upload page
open http://localhost:3004/admin/upload

# View logs
# (Check browser console for errors)
```

---

**Current Status:** Week 4 Day 1 - Setup phase complete, ready for testing!

**Last Updated:** October 16, 2025
